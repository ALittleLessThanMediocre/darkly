## Introduction:

This is the description of a Robots.txt file, according to portswigger.net

"The file robots.txt is used to give instructions to web robots, such as search engine crawlers, 
about locations within the web site that robots are allowed, or not allowed, to crawl and index.

The presence of the robots.txt does not in itself present any kind of security vulnerability.
However, it is often used to identify restricted or private areas of a site's contents. 
The information in the file may therefore help an attacker to map out the site's contents, 
especially if some of the locations identified are not linked from elsewhere in the site. 
If the application relies on robots.txt to protect access to these areas, 
and does not enforce proper access control over them, then this presents a serious vulnerability."

## Where to Locate:

We can find this file on the root of the site at the address, http://$IP/robots.txt

## Exploit:

There we find two routes that are not accessible through the normal navigating of the site
These two routes being, /whatever, and /.hidden

Entering the directory /whatever, we find a file htpasswd, within that file we find the following string
"root:8621ffdbc5698829397d97767ac13db3"

Which we can infer to be a username and an md5 hashed password from the name of the file they exist within.
Decrypting the password we receive the word "dragon".
Because the username is root, we can make the reasonable assumption that these are the site's admin credentials.

Entering common admin url names we finally succeed with the url, http://$IP/admin

Submiting the credentials gives us access to the admin page and we receive a flag and some nice visuals.
flag = d19b4823e0d5600ceed56d5e896ef328d7a2b9e7ac7e80f4fcdb9b10bcb3e7ff

## Prevention:

Access control vulnerabilities can generally be prevented by taking a defense-in-depth approach and applying the following principles: 

- Never rely on obfuscation alone for access control.
- Unless a resource is intended to be publicly accessible, deny access by default.
- Wherever possible, use a single application-wide mechanism for enforcing access controls.
- At the code level, make it mandatory for developers to declare the access that is allowed for each resource, and deny access by default. 
- Thoroughly audit and test access controls to ensure they are working as designed.  